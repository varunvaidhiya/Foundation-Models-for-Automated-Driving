{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Florence 2\n",
    "Provide a brief overview of the Florence 2 model, its architecture, and its applications in object detection and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of Florence 2\n",
    "\n",
    "Florence 2 is a state-of-the-art vision model developed for advanced object detection and classification tasks. It builds upon the success of its predecessor, Florence, by incorporating the latest advancements in deep learning and computer vision. The model is designed to be highly efficient and accurate, making it suitable for a wide range of applications, from autonomous vehicles to content moderation in social media platforms.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "Florence 2 utilizes a transformer-based architecture, which allows it to effectively capture long-range dependencies in the input data. This is particularly beneficial for complex scenes where objects may be partially obscured or interact with each other in intricate ways. The model also employs a multi-scale feature extraction technique, enabling it to detect objects of various sizes with high precision.\n",
    "\n",
    "## Applications\n",
    "\n",
    "The primary applications of Florence 2 include object detection and classification. In object detection, the model can identify and locate multiple objects within an image, providing bounding boxes and class labels for each detected object. For classification, Florence 2 can accurately categorize the primary subject of an image among a predefined set of classes. This versatility makes Florence 2 an excellent choice for tasks ranging from surveillance and security to wildlife monitoring and urban planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Environment\n",
    "Guide on setting up the development environment, including the installation of necessary libraries and frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Up the Environment\n",
    "\n",
    "# Install necessary libraries and frameworks\n",
    "!pip install torch torchvision\n",
    "!pip install transformers\n",
    "!pip install florence2\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Check if CUDA is available for GPU acceleration\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU acceleration can be utilized.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training will proceed on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Fine-Tuning a Pretrained Model\n",
    "Demonstrate how to fine-tune a pretrained Florence 2 model using PyTorch for a custom object detection or classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained Florence 2 model\n",
    "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
    "model_name = \"microsoft/florence2-base\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Prepare a custom dataset for fine-tuning\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\"path/to/your/dataset\", transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Define the training loop\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "# Define the validation loop\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "# Fine-tune the model\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras: Fine-Tuning a Pretrained Model\n",
    "Show how to fine-tune a pretrained Florence 2 model using TensorFlow and Keras for a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and Keras: Fine-Tuning a Pretrained Model\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load and preprocess the dataset for TensorFlow\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = keras.applications.resnet.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def prepare_dataset(dataset_path, batch_size=32):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical'\n",
    "    ).map(lambda x, y: (preprocess_image(x), y))\n",
    "    return dataset\n",
    "\n",
    "# Prepare TensorFlow dataset\n",
    "dataset_path = \"path/to/your/dataset\"\n",
    "batch_size = 32\n",
    "tf_dataset = prepare_dataset(dataset_path, batch_size)\n",
    "tf_train_dataset = tf_dataset.take(int(0.8 * len(tf_dataset)))\n",
    "tf_val_dataset = tf_dataset.skip(int(0.8 * len(tf_dataset)))\n",
    "\n",
    "# Load a pretrained model\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(len(dataset.classes), activation='softmax')  # Assuming 'dataset' has a 'classes' attribute\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(tf_train_dataset, validation_data=tf_val_dataset, epochs=5)\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  # Example: unfreeze layers from this layer onwards\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model (necessary after modifying layer.trainability)\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Lower learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training (fine-tuning)\n",
    "fine_tune_epochs = 5\n",
    "total_epochs = epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(tf_train_dataset,\n",
    "                         validation_data=tf_val_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2: Fine-Tuning for Object Detection\n",
    "Explain how to use Detectron2 for fine-tuning Florence 2 on an object detection task, including dataset preparation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Detectron2\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.8/index.html\n",
    "\n",
    "# Import Detectron2 utilities\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# Register the custom dataset for Detectron2\n",
    "dataset_name = \"custom_dataset\"\n",
    "dataset_path = \"path/to/your/dataset\"\n",
    "json_annotation = \"path/to/your/annotation.json\"\n",
    "\n",
    "register_coco_instances(dataset_name, {}, json_annotation, dataset_path)\n",
    "\n",
    "# Prepare the Detectron2 configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (dataset_name,)\n",
    "cfg.DATASETS.TEST = ()  # No testing dataset\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.02\n",
    "cfg.SOLVER.MAX_ITER = 1000  # Adjust according to dataset size\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(dataset_name).thing_classes)  # Set the number of classes\n",
    "\n",
    "# Initialize the Detectron2 trainer and start fine-tuning\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMdetection: Fine-Tuning for Object Detection\n",
    "Detail the process of fine-tuning Florence 2 with MMdetection for object detection, covering dataset setup and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MMdetection\n",
    "!pip install openmim\n",
    "!mim install mmdet\n",
    "\n",
    "# Import MMdetection utilities\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmcv import Config\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "# Load configuration file for fine-tuning\n",
    "config_file = 'path/to/your/config.py'  # Specify the path to the MMdetection config file tailored for Florence 2\n",
    "checkpoint_file = 'path/to/your/checkpoint.pth'  # Specify the path to the pretrained Florence 2 weights if available\n",
    "\n",
    "# Modify the configuration to adapt to your dataset\n",
    "cfg = Config.fromfile(config_file)\n",
    "cfg.model.pretrained = None  # We are fine-tuning, so we don't need the pretrained weights\n",
    "cfg.data.train.ann_file = 'path/to/your/train/annotation.json'  # Path to training annotations in COCO format\n",
    "cfg.data.train.img_prefix = 'path/to/your/train/images/'  # Path to training images\n",
    "cfg.data.val.ann_file = 'path/to/your/val/annotation.json'  # Path to validation annotations in COCO format\n",
    "cfg.data.val.img_prefix = 'path/to/your/val/images/'  # Path to validation images\n",
    "cfg.data.test.ann_file = 'path/to/your/test/annotation.json'  # Path to test annotations in COCO format\n",
    "cfg.data.test.img_prefix = 'path/to/your/test/images/'  # Path to test images\n",
    "\n",
    "# Adjust the number of classes based on your dataset\n",
    "cfg.model.roi_head.bbox_head.num_classes = len(dataset.classes)  # Assuming 'dataset' has a 'classes' attribute\n",
    "\n",
    "# Adjust the learning rate and other hyperparameters based on your dataset size and desired training duration\n",
    "cfg.optimizer.lr = 1e-4\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Build dataset and model\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Fine-tune the model\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
